# Low Competition Test (1-3 pods)
---
apiVersion: v1
kind: Pod
metadata:
  name: small-regression-low-1
  annotations:
    task.type: "compute_intensive"
    task.loc: "110" 
    task.source: |
      package com.process.tasks;

      import java.io.*;
      import java.util.ArrayList;
      import java.util.Arrays;
      import java.util.List;
      import java.util.Random;

      public class LinearRegressionSmallDataset {
          private double weight;    // slope
          private double bias;      // intercept
          private double r2Score;   // R-squared value for model evaluation

          // Train the model
          public void fit(double[] x, double[] y) {
              if (x.length != y.length) {
                  throw new IllegalArgumentException("Input arrays must have the same length");
              }
              if (x.length == 0) {
                  throw new IllegalArgumentException("Input arrays cannot be empty");
              }

              double xMean = Arrays.stream(x).average().orElse(0.0);
              double yMean = Arrays.stream(y).average().orElse(0.0);

              // Calculate the weight (slope)
              double numerator = 0;
              double denominator = 0;
              for (int i = 0; i < x.length; i++) {
                  numerator += (x[i] - xMean) * (y[i] - yMean);
                  denominator += Math.pow(x[i] - xMean, 2);
              }
              weight = numerator / denominator;

              // Calculate the bias (intercept)
              bias = yMean - weight * xMean;

              // Calculate R-squared
              calculateR2Score(x, y, yMean);
          }

          // Calculate R-squared score
          private void calculateR2Score(double[] x, double[] y, double yMean) {
              double totalSS = 0;
              double residualSS = 0;
              
              for (int i = 0; i < x.length; i++) {
                  double predicted = predict(x[i]);
                  residualSS += Math.pow(y[i] - predicted, 2);
                  totalSS += Math.pow(y[i] - yMean, 2);
              }
              
              r2Score = 1 - (residualSS / totalSS);
          }

          // Predict the output for a new input
          public double predict(double x) {
              return weight * x + bias;
          }

          // Get model metrics
          public String getModelMetrics() {
              return String.format(
                  "Model Metrics:\nSlope (weight): %.4f\nIntercept (bias): %.4f\nR-squared: %.4f",
                  weight, bias, r2Score
              );
          }

          // Load dataset from CSV with validation
          public static double[][] loadDataset(String filePath) throws IOException {
              List<Double> sizes = new ArrayList<>();
              List<Double> prices = new ArrayList<>();
              
              try (BufferedReader br = new BufferedReader(new FileReader(filePath))) {
                  String line = br.readLine(); // Skip header
                  if (line == null) {
                      throw new IOException("Empty file");
                  }
                  
                  int lineNumber = 1;
                  while ((line = br.readLine()) != null) {
                      lineNumber++;
                      try {
                          String[] values = line.split(",");
                          if (values.length != 2) {
                              System.err.println("Warning: Invalid data format at line " + lineNumber + ", skipping...");
                              continue;
                          }
                          
                          double size = Double.parseDouble(values[0].trim());
                          double price = Double.parseDouble(values[1].trim());
                          
                          // Basic data validation
                          if (size <= 0 || price <= 0) {
                              System.err.println("Warning: Invalid values at line " + lineNumber + ", skipping...");
                              continue;
                          }
                          
                          sizes.add(size);
                          prices.add(price);
                      } catch (NumberFormatException e) {
                          System.err.println("Warning: Invalid number format at line " + lineNumber + ", skipping...");
                      }
                  }
              }
              
              if (sizes.isEmpty()) {
                  throw new IOException("No valid data found in the file");
              }

              double[] sizeArray = sizes.stream().mapToDouble(Double::doubleValue).toArray();
              double[] priceArray = prices.stream().mapToDouble(Double::doubleValue).toArray();
              return new double[][] { sizeArray, priceArray };
          }

          // Generate sample dataset
          public static void generateSampleDataset(String filePath, int numSamples) throws IOException {
              try (PrintWriter writer = new PrintWriter(new FileWriter(filePath))) {
                  writer.println("size,price");
                  Random random = new Random();
                  
                  // Generate realistic house data with some noise
                  for (int i = 0; i < numSamples; i++) {
                      double size = 1000 + random.nextDouble() * 3000; // House sizes between 1000-4000 sq ft
                      // Price formula: base price + (price per sq ft * size) + random noise
                      double price = 100 + (0.2 * size) + (random.nextGaussian() * 50);
                      writer.printf("%.2f,%.2f%n", size, price);
                  }
              }
          }

          public static void main(String[] args) {
              try {
                  // Generate sample dataset
                  String filePath = "house_prices.csv";
                  generateSampleDataset(filePath, 1000);
                  System.out.println("Generated sample dataset: " + filePath);

                  // Load dataset
                  double[][] data = loadDataset(filePath);
                  double[] houseSizes = data[0];
                  double[] housePrices = data[1];

                  // Train the model
                  LinearRegressionSmallDataset lr = new LinearRegressionSmallDataset();
                  lr.fit(houseSizes, housePrices);

                  // Print model metrics
                  System.out.println("\n" + lr.getModelMetrics());

                  // Test predictions for different house sizes
                  double[] testSizes = {1500, 2000, 2500, 3000, 3500};
                  System.out.println("\nPredictions for different house sizes:");
                  for (double size : testSizes) {
                      double predictedPrice = lr.predict(size);
                      System.out.printf("Size: %.0f sq ft -> Predicted price: $%.2fk%n", size, predictedPrice);
                  }

              } catch (IOException e) {
                  System.err.println("Error: " + e.getMessage());
              } catch (IllegalArgumentException e) {
                  System.err.println("Error in data processing: " + e.getMessage());
              }
          }
      }
spec:
  schedulerName: topsis-scheduler
  containers:
  - name: small-regression
    image: ppreejit/small-regression:latest
    resources:
      requests:
        cpu: "100m"
        memory: "256Mi"
      limits:
        cpu: "200m"
        memory: "512Mi"
    volumeMounts:
    - name: data-volume
      mountPath: /app/data
  volumes:
  - name: data-volume
    emptyDir: {}
  tolerations:
  - key: "cloud.google.com/gke-spot"
    operator: "Equal"
    value: "true"
    effect: "NoSchedule"
---
apiVersion: v1
kind: Pod
metadata:
  name: scalable-regression-low-1
  annotations:
    task.type: "compute_intensive"
    task.loc: "185"
    task.source: |
      package com.process.tasks;

      import java.io.*;
      import java.util.ArrayList;
      import java.util.Iterator;
      import java.util.List;
      import java.util.Random;
      import java.util.concurrent.*;
      import java.nio.file.*;
      import java.util.stream.*;

      public class ScalableLinearRegression {
          private double weight;
          private double bias;
          private double r2Score;
          private final int batchSize;
          private final int numThreads;
          
          public ScalableLinearRegression(int batchSize, int numThreads) {
              this.batchSize = batchSize;
              this.numThreads = numThreads;
          }

          // Batch statistics calculator for parallel processing
          private static class BatchStatistics {
              double sumX = 0;
              double sumY = 0;
              double sumXY = 0;
              double sumXSquared = 0;
              int count = 0;
              
              void update(double x, double y) {
                  sumX += x;
                  sumY += y;
                  sumXY += x * y;
                  sumXSquared += x * x;
                  count++;
              }
              
              void combine(BatchStatistics other) {
                  sumX += other.sumX;
                  sumY += other.sumY;
                  sumXY += other.sumXY;
                  sumXSquared += other.sumXSquared;
                  count += other.count;
              }
          }

          // Fit the model using batched processing
          public void fit(String dataFile) throws IOException, InterruptedException, ExecutionException {
              ExecutorService executor = Executors.newFixedThreadPool(numThreads);
              List<Future<BatchStatistics>> futures = new ArrayList<>();
              
              // First pass: Calculate means and basic statistics
              try (Stream<String> lines = Files.lines(Paths.get(dataFile)).skip(1)) {
                  List<List<String>> batches = new ArrayList<>();
                  List<String> currentBatch = new ArrayList<>();
                  
                  Iterator<String> iterator = lines.iterator();
                  while (iterator.hasNext()) {
                      currentBatch.add(iterator.next());
                      if (currentBatch.size() >= batchSize) {
                          batches.add(new ArrayList<>(currentBatch));
                          currentBatch.clear();
                      }
                  }
                  if (!currentBatch.isEmpty()) {
                      batches.add(currentBatch);
                  }

                  // Process batches in parallel
                  for (List<String> batch : batches) {
                      futures.add(executor.submit(() -> processBatch(batch)));
                  }
              }

              // Combine results
              BatchStatistics totalStats = new BatchStatistics();
              for (Future<BatchStatistics> future : futures) {
                  totalStats.combine(future.get());
              }

              // Calculate final parameters
              double xMean = totalStats.sumX / totalStats.count;
              double yMean = totalStats.sumY / totalStats.count;
              
              weight = (totalStats.sumXY - (totalStats.sumX * totalStats.sumY / totalStats.count)) /
                      (totalStats.sumXSquared - (totalStats.sumX * totalStats.sumX / totalStats.count));
              bias = yMean - weight * xMean;

              // Calculate R-squared using streaming
              calculateR2Score(dataFile, yMean);
              
              executor.shutdown();
          }

          private BatchStatistics processBatch(List<String> batch) {
              BatchStatistics stats = new BatchStatistics();
              for (String line : batch) {
                  String[] values = line.split(",");
                  double x = Double.parseDouble(values[0].trim());
                  double y = Double.parseDouble(values[1].trim());
                  stats.update(x, y);
              }
              return stats;
          }

          private void calculateR2Score(String dataFile, double yMean) throws IOException {
              try (Stream<String> lines = Files.lines(Paths.get(dataFile)).skip(1)) {
                  double[] sums = lines.parallel()
                      .map(line -> line.split(","))
                      .map(values -> {
                          double x = Double.parseDouble(values[0].trim());
                          double y = Double.parseDouble(values[1].trim());
                          double predicted = predict(x);
                          return new double[] {
                              Math.pow(y - predicted, 2),  // residual SS
                              Math.pow(y - yMean, 2)       // total SS
                          };
                      })
                      .reduce(
                          new double[] {0.0, 0.0},
                          (a, b) -> new double[] {a[0] + b[0], a[1] + b[1]}
                      );
                  
                  r2Score = 1 - (sums[0] / sums[1]);
              }
          }

          public double predict(double x) {
              return weight * x + bias;
          }

          public String getModelMetrics() {
              return String.format(
                  "Model Metrics:\nSlope (weight): %.4f\nIntercept (bias): %.4f\nR-squared: %.4f",
                  weight, bias, r2Score
              );
          }

          // Enhanced data generation for large datasets
          public static void generateLargeDataset(String filePath, int numSamples) throws IOException {
              int batchSize = 10000;
              try (BufferedWriter writer = Files.newBufferedWriter(Paths.get(filePath))) {
                  writer.write("size,price\n");
                  Random random = new Random();
                  
                  for (int i = 0; i < numSamples; i += batchSize) {
                      StringBuilder batch = new StringBuilder();
                      int currentBatchSize = Math.min(batchSize, numSamples - i);
                      
                      for (int j = 0; j < currentBatchSize; j++) {
                          double size = 1000 + random.nextDouble() * 3000;
                          double price = 100 + (0.2 * size) + (random.nextGaussian() * 50);
                          batch.append(String.format("%.2f,%.2f%n", size, price));
                      }
                      writer.write(batch.toString());
                  }
              }
          }

          public static void main(String[] args) {
              try {
                  String filePath = "large_house_prices.csv";
                  int numSamples = 1_000_000;  // 1 million samples
                  
                  // Generate large dataset
                  System.out.println("Generating large dataset...");
                  generateLargeDataset(filePath, numSamples);
                  
                  // Create and train model
                  ScalableLinearRegression model = new ScalableLinearRegression(
                      10000,  // batch size
                      Runtime.getRuntime().availableProcessors()  // use all available cores
                  );
                  
                  System.out.println("Training model...");
                  long startTime = System.currentTimeMillis();
                  model.fit(filePath);
                  long endTime = System.currentTimeMillis();
                  
                  System.out.println("\nTraining completed in " + (endTime - startTime) / 1000.0 + " seconds");
                  System.out.println(model.getModelMetrics());
                  
                  // Test predictions
                  System.out.println("\nSample predictions:");
                  double[] testSizes = {1500, 2000, 2500, 3000, 3500};
                  for (double size : testSizes) {
                      System.out.printf(
                          "Size: %.0f sq ft -> Predicted price: $%.2fk%n",
                          size, model.predict(size)
                      );
                  }
                  
              } catch (Exception e) {
                  System.err.println("Error: " + e.getMessage());
                  e.printStackTrace();
              }
          }
      }
spec:
  schedulerName: topsis-scheduler
  containers:
  - name: scalable-regression
    image: ppreejit/scalable-regression:latest
    resources:
      requests:
        cpu: "500m"
        memory: "512Mi"
      limits:
        cpu: "1000m"
        memory: "1Gi"
    env:
    - name: BATCH_SIZE
      value: "10000"
    - name: NUM_THREADS
      value: "4"
    volumeMounts:
    - name: data-volume
      mountPath: /app/data
  volumes:
  - name: data-volume
    emptyDir: {}
  tolerations:
  - key: "cloud.google.com/gke-spot"
    operator: "Equal"
    value: "true"
    effect: "NoSchedule"

---
apiVersion: v1
kind: Pod
metadata:
  name: small-regression-low-1-default
  annotations:
    task.type: "compute_intensive"
    task.loc: "110" 
    task.source: |
      package com.process.tasks;

      import java.io.*;
      import java.util.ArrayList;
      import java.util.Arrays;
      import java.util.List;
      import java.util.Random;

      public class LinearRegressionSmallDataset {
          private double weight;    // slope
          private double bias;      // intercept
          private double r2Score;   // R-squared value for model evaluation

          // Train the model
          public void fit(double[] x, double[] y) {
              if (x.length != y.length) {
                  throw new IllegalArgumentException("Input arrays must have the same length");
              }
              if (x.length == 0) {
                  throw new IllegalArgumentException("Input arrays cannot be empty");
              }

              double xMean = Arrays.stream(x).average().orElse(0.0);
              double yMean = Arrays.stream(y).average().orElse(0.0);

              // Calculate the weight (slope)
              double numerator = 0;
              double denominator = 0;
              for (int i = 0; i < x.length; i++) {
                  numerator += (x[i] - xMean) * (y[i] - yMean);
                  denominator += Math.pow(x[i] - xMean, 2);
              }
              weight = numerator / denominator;

              // Calculate the bias (intercept)
              bias = yMean - weight * xMean;

              // Calculate R-squared
              calculateR2Score(x, y, yMean);
          }

          // Calculate R-squared score
          private void calculateR2Score(double[] x, double[] y, double yMean) {
              double totalSS = 0;
              double residualSS = 0;
              
              for (int i = 0; i < x.length; i++) {
                  double predicted = predict(x[i]);
                  residualSS += Math.pow(y[i] - predicted, 2);
                  totalSS += Math.pow(y[i] - yMean, 2);
              }
              
              r2Score = 1 - (residualSS / totalSS);
          }

          // Predict the output for a new input
          public double predict(double x) {
              return weight * x + bias;
          }

          // Get model metrics
          public String getModelMetrics() {
              return String.format(
                  "Model Metrics:\nSlope (weight): %.4f\nIntercept (bias): %.4f\nR-squared: %.4f",
                  weight, bias, r2Score
              );
          }

          // Load dataset from CSV with validation
          public static double[][] loadDataset(String filePath) throws IOException {
              List<Double> sizes = new ArrayList<>();
              List<Double> prices = new ArrayList<>();
              
              try (BufferedReader br = new BufferedReader(new FileReader(filePath))) {
                  String line = br.readLine(); // Skip header
                  if (line == null) {
                      throw new IOException("Empty file");
                  }
                  
                  int lineNumber = 1;
                  while ((line = br.readLine()) != null) {
                      lineNumber++;
                      try {
                          String[] values = line.split(",");
                          if (values.length != 2) {
                              System.err.println("Warning: Invalid data format at line " + lineNumber + ", skipping...");
                              continue;
                          }
                          
                          double size = Double.parseDouble(values[0].trim());
                          double price = Double.parseDouble(values[1].trim());
                          
                          // Basic data validation
                          if (size <= 0 || price <= 0) {
                              System.err.println("Warning: Invalid values at line " + lineNumber + ", skipping...");
                              continue;
                          }
                          
                          sizes.add(size);
                          prices.add(price);
                      } catch (NumberFormatException e) {
                          System.err.println("Warning: Invalid number format at line " + lineNumber + ", skipping...");
                      }
                  }
              }
              
              if (sizes.isEmpty()) {
                  throw new IOException("No valid data found in the file");
              }

              double[] sizeArray = sizes.stream().mapToDouble(Double::doubleValue).toArray();
              double[] priceArray = prices.stream().mapToDouble(Double::doubleValue).toArray();
              return new double[][] { sizeArray, priceArray };
          }

          // Generate sample dataset
          public static void generateSampleDataset(String filePath, int numSamples) throws IOException {
              try (PrintWriter writer = new PrintWriter(new FileWriter(filePath))) {
                  writer.println("size,price");
                  Random random = new Random();
                  
                  // Generate realistic house data with some noise
                  for (int i = 0; i < numSamples; i++) {
                      double size = 1000 + random.nextDouble() * 3000; // House sizes between 1000-4000 sq ft
                      // Price formula: base price + (price per sq ft * size) + random noise
                      double price = 100 + (0.2 * size) + (random.nextGaussian() * 50);
                      writer.printf("%.2f,%.2f%n", size, price);
                  }
              }
          }

          public static void main(String[] args) {
              try {
                  // Generate sample dataset
                  String filePath = "house_prices.csv";
                  generateSampleDataset(filePath, 1000);
                  System.out.println("Generated sample dataset: " + filePath);

                  // Load dataset
                  double[][] data = loadDataset(filePath);
                  double[] houseSizes = data[0];
                  double[] housePrices = data[1];

                  // Train the model
                  LinearRegressionSmallDataset lr = new LinearRegressionSmallDataset();
                  lr.fit(houseSizes, housePrices);

                  // Print model metrics
                  System.out.println("\n" + lr.getModelMetrics());

                  // Test predictions for different house sizes
                  double[] testSizes = {1500, 2000, 2500, 3000, 3500};
                  System.out.println("\nPredictions for different house sizes:");
                  for (double size : testSizes) {
                      double predictedPrice = lr.predict(size);
                      System.out.printf("Size: %.0f sq ft -> Predicted price: $%.2fk%n", size, predictedPrice);
                  }

              } catch (IOException e) {
                  System.err.println("Error: " + e.getMessage());
              } catch (IllegalArgumentException e) {
                  System.err.println("Error in data processing: " + e.getMessage());
              }
          }
      }
spec:
  containers:
  - name: small-regression
    image: ppreejit/small-regression:latest
    resources:
      requests:
        cpu: "100m"
        memory: "256Mi"
      limits:
        cpu: "200m"
        memory: "512Mi"
    volumeMounts:
    - name: data-volume
      mountPath: /app/data
  volumes:
  - name: data-volume
    emptyDir: {}
  tolerations:
  - key: "cloud.google.com/gke-spot"
    operator: "Equal"
    value: "true"
    effect: "NoSchedule"
---
apiVersion: v1
kind: Pod
metadata:
  name: scalable-regression-low-1-default
  annotations:
    task.type: "compute_intensive"
    task.loc: "185"
    task.source: |
      package com.process.tasks;

      import java.io.*;
      import java.util.ArrayList;
      import java.util.Iterator;
      import java.util.List;
      import java.util.Random;
      import java.util.concurrent.*;
      import java.nio.file.*;
      import java.util.stream.*;

      public class ScalableLinearRegression {
          private double weight;
          private double bias;
          private double r2Score;
          private final int batchSize;
          private final int numThreads;
          
          public ScalableLinearRegression(int batchSize, int numThreads) {
              this.batchSize = batchSize;
              this.numThreads = numThreads;
          }

          // Batch statistics calculator for parallel processing
          private static class BatchStatistics {
              double sumX = 0;
              double sumY = 0;
              double sumXY = 0;
              double sumXSquared = 0;
              int count = 0;
              
              void update(double x, double y) {
                  sumX += x;
                  sumY += y;
                  sumXY += x * y;
                  sumXSquared += x * x;
                  count++;
              }
              
              void combine(BatchStatistics other) {
                  sumX += other.sumX;
                  sumY += other.sumY;
                  sumXY += other.sumXY;
                  sumXSquared += other.sumXSquared;
                  count += other.count;
              }
          }

          // Fit the model using batched processing
          public void fit(String dataFile) throws IOException, InterruptedException, ExecutionException {
              ExecutorService executor = Executors.newFixedThreadPool(numThreads);
              List<Future<BatchStatistics>> futures = new ArrayList<>();
              
              // First pass: Calculate means and basic statistics
              try (Stream<String> lines = Files.lines(Paths.get(dataFile)).skip(1)) {
                  List<List<String>> batches = new ArrayList<>();
                  List<String> currentBatch = new ArrayList<>();
                  
                  Iterator<String> iterator = lines.iterator();
                  while (iterator.hasNext()) {
                      currentBatch.add(iterator.next());
                      if (currentBatch.size() >= batchSize) {
                          batches.add(new ArrayList<>(currentBatch));
                          currentBatch.clear();
                      }
                  }
                  if (!currentBatch.isEmpty()) {
                      batches.add(currentBatch);
                  }

                  // Process batches in parallel
                  for (List<String> batch : batches) {
                      futures.add(executor.submit(() -> processBatch(batch)));
                  }
              }

              // Combine results
              BatchStatistics totalStats = new BatchStatistics();
              for (Future<BatchStatistics> future : futures) {
                  totalStats.combine(future.get());
              }

              // Calculate final parameters
              double xMean = totalStats.sumX / totalStats.count;
              double yMean = totalStats.sumY / totalStats.count;
              
              weight = (totalStats.sumXY - (totalStats.sumX * totalStats.sumY / totalStats.count)) /
                      (totalStats.sumXSquared - (totalStats.sumX * totalStats.sumX / totalStats.count));
              bias = yMean - weight * xMean;

              // Calculate R-squared using streaming
              calculateR2Score(dataFile, yMean);
              
              executor.shutdown();
          }

          private BatchStatistics processBatch(List<String> batch) {
              BatchStatistics stats = new BatchStatistics();
              for (String line : batch) {
                  String[] values = line.split(",");
                  double x = Double.parseDouble(values[0].trim());
                  double y = Double.parseDouble(values[1].trim());
                  stats.update(x, y);
              }
              return stats;
          }

          private void calculateR2Score(String dataFile, double yMean) throws IOException {
              try (Stream<String> lines = Files.lines(Paths.get(dataFile)).skip(1)) {
                  double[] sums = lines.parallel()
                      .map(line -> line.split(","))
                      .map(values -> {
                          double x = Double.parseDouble(values[0].trim());
                          double y = Double.parseDouble(values[1].trim());
                          double predicted = predict(x);
                          return new double[] {
                              Math.pow(y - predicted, 2),  // residual SS
                              Math.pow(y - yMean, 2)       // total SS
                          };
                      })
                      .reduce(
                          new double[] {0.0, 0.0},
                          (a, b) -> new double[] {a[0] + b[0], a[1] + b[1]}
                      );
                  
                  r2Score = 1 - (sums[0] / sums[1]);
              }
          }

          public double predict(double x) {
              return weight * x + bias;
          }

          public String getModelMetrics() {
              return String.format(
                  "Model Metrics:\nSlope (weight): %.4f\nIntercept (bias): %.4f\nR-squared: %.4f",
                  weight, bias, r2Score
              );
          }

          // Enhanced data generation for large datasets
          public static void generateLargeDataset(String filePath, int numSamples) throws IOException {
              int batchSize = 10000;
              try (BufferedWriter writer = Files.newBufferedWriter(Paths.get(filePath))) {
                  writer.write("size,price\n");
                  Random random = new Random();
                  
                  for (int i = 0; i < numSamples; i += batchSize) {
                      StringBuilder batch = new StringBuilder();
                      int currentBatchSize = Math.min(batchSize, numSamples - i);
                      
                      for (int j = 0; j < currentBatchSize; j++) {
                          double size = 1000 + random.nextDouble() * 3000;
                          double price = 100 + (0.2 * size) + (random.nextGaussian() * 50);
                          batch.append(String.format("%.2f,%.2f%n", size, price));
                      }
                      writer.write(batch.toString());
                  }
              }
          }

          public static void main(String[] args) {
              try {
                  String filePath = "large_house_prices.csv";
                  int numSamples = 1_000_000;  // 1 million samples
                  
                  // Generate large dataset
                  System.out.println("Generating large dataset...");
                  generateLargeDataset(filePath, numSamples);
                  
                  // Create and train model
                  ScalableLinearRegression model = new ScalableLinearRegression(
                      10000,  // batch size
                      Runtime.getRuntime().availableProcessors()  // use all available cores
                  );
                  
                  System.out.println("Training model...");
                  long startTime = System.currentTimeMillis();
                  model.fit(filePath);
                  long endTime = System.currentTimeMillis();
                  
                  System.out.println("\nTraining completed in " + (endTime - startTime) / 1000.0 + " seconds");
                  System.out.println(model.getModelMetrics());
                  
                  // Test predictions
                  System.out.println("\nSample predictions:");
                  double[] testSizes = {1500, 2000, 2500, 3000, 3500};
                  for (double size : testSizes) {
                      System.out.printf(
                          "Size: %.0f sq ft -> Predicted price: $%.2fk%n",
                          size, model.predict(size)
                      );
                  }
                  
              } catch (Exception e) {
                  System.err.println("Error: " + e.getMessage());
                  e.printStackTrace();
              }
          }
      }
spec:
  containers:
  - name: scalable-regression
    image: ppreejit/scalable-regression:latest
    resources:
      requests:
        cpu: "500m"
        memory: "512Mi"
      limits:
        cpu: "1000m"
        memory: "1Gi"
    env:
    - name: BATCH_SIZE
      value: "10000"
    - name: NUM_THREADS
      value: "4"
    volumeMounts:
    - name: data-volume
      mountPath: /app/data
  volumes:
  - name: data-volume
    emptyDir: {}
  tolerations:
  - key: "cloud.google.com/gke-spot"
    operator: "Equal"
    value: "true"
    effect: "NoSchedule"